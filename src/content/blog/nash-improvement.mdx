---
title: 'Visualizing the Nash Improvement Function'
description: 'Exploring Mixed Nash Equilibria, Fixed Points, and Gradients'
pubDate: 'May 01 2025'
---
import D3Visualization from "../../components/nash-improvement/nash-field.tsx";

This semester, I took CS 839: Game Theory, Optimization, and Learning with Profesor [Vlatakis-Gkaragkounis](https://pages.cs.wisc.edu/~vlatakis/). We studied the theoretical foundations of Nash Equlibriums, fixed points, gradient descent, reinforcement learning, etc. I wanted to take a moment to talk about Nash Equilibriums and show off a cool visualization that demonstrates some of those theories intuitively. But first, some background.

## Nash Equilibriums

Nash Equilibriums are when all players in a game each have no incentive to change their strategies. These strategies could be always doing the same action, called a **pure strategy** or could be a distribution across a range of strategies, called a **mixed strategy**. For this post and the visualization, we focus on simple games with only two actions for each player and only two players.

In formal math terms, $x_i \in \Delta(A_i)$ is the strategy (mixed or pure) for player $i$. Because it is a probability distribution, it is a vector and its components must add to $1$. This fact is denoted by the strategy belonging to the [simplex](https://en.wikipedia.org/wiki/Simplex) $\Delta(A_i)$, where $A_i$ denotes the actions available to player $i$. 

For example, $x_1 = \begin{bmatrix} 1 & 0 \end{bmatrix}$ represents a pure strategy for player 1 of doing the first action 100% of the time. Alternatively, $x_2 = \begin{bmatrix} 0.75 & 0.25 \end{bmatrix}$ is a mixed strategy for player 2 that plays action (1) 75% of the time, and action (2) 25%.

## The Nash Improvement Function and Fixed Points
<style>
    {`
    .frac-line{
		border-color: black;
    `}
</style>

If our goal is to find Nash Equilibria, then we should use the Nash improvement function, which was first introduced by John Nash. Let $x_1 \in \Delta(A_1), \ldots, x_n \in \Delta(A_n)$ be strategies. Then, the Nash improvement function $\psi: \Delta(A_1) \times \ldots \times \Delta(A_n) \rightarrow \Delta(A_1) \times \ldots \times \Delta(A_n)$ maps all current user strategies to those "closer" to a Nash Equilibrium:
$$
\psi_{i, a_i}(x_1, \ldots, x_n) := \frac{x_{i,a_i} + \left[ r_{i,a_i}(x_1, \ldots, x_n) \right]^+}{1 + \sum_{a'_i \in A_i}\left[r_{i, a'_i}(x_1, \ldots, x_n)\right]^+}
$$

for all players $i \in [n]$ and action $a_i \in A_i$ where $[h]^+ := \max\{0, r\}$ bounds reward values to be non-negative. If the input is already a Nash Equilibrium, then it will output the same strategy because there is no improvement to make. This makes a Nash Equilibrium a fixed point in the Nash improvement Function. There's additional work proving the existence of a Nash Equilibrium using [Brouwer's fixed-point theorem](https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem). In the general case, finding a fixed point is a computationally intractible problem (PPAD), 


## The Cool, Interactive Visualization

The homework assignment that inspired this post was in turn inspired by the visualizations from an [MIT lecture on Game Theory](https://www.mit.edu/~gfarina/2024/6S890f24_L02_nfg_nash/L02.pdf). Some mathematical definitions are taken from these two sources.

<D3Visualization client:load />


## Technical Details
The interactive portion of this blog post is a React component that renders client side. The visuals were made using [D3.js](https://d3js.org/). I "vibe-coded" some of the styling for the UI using claude.
